{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font face=\"Times New Roman\" size=5><div dir=ltr align=center>\n",
    "<font color=blue size=8>\n",
    "    Introduction to Machine Learning <br>\n",
    "<font color=red size=5>\n",
    "    Sharif University of Technology - Computer Engineering Department <br>\n",
    "    Fall 2022<br> <br>\n",
    "<font color=black size=6>\n",
    "    Homework 2: Practical - Linear Regression\n",
    "    </div>\n",
    "<br><br>\n",
    "<font size=4>\n",
    "   **Name**: Mohammad Mahdi<br>\n",
    "   **Student ID**: 98105557<br> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Times New Roman\" size=4><div dir=ltr>\n",
    "# Problem 1: Linear Regression Model (40 + 30 optional points)\n",
    "According to <a href=\"https://github.com/asharifiz/Introduction_to_Machine_Learning/blob/main/Jupyter_Notebooks/Chapter_02_Classical_Models/Linear%20regression.ipynb\"><font face=\"Roboto\">Linear Regression Notebook</font></a>, train a linear regression model on an arbitrary dataset. Explain your chosen dataset and split your data into train and test sets, then predict values for the test set using your trained model. Try to find the best hyperparameters for your model. (Using Lasso Regression, Ridge Regression or Elastic Net and comparing them will have extra optional points)\n",
    "<br> Explain each step of your workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mahdi\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading dataset\n",
    "This dataset is Tesla's stock from 2010 to 2020. it has some columns of opening price or highest and lowest price of the day. we try to predict closing/the last price of the stock based on the other features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-06-29</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>25.00</td>\n",
       "      <td>17.540001</td>\n",
       "      <td>23.889999</td>\n",
       "      <td>23.889999</td>\n",
       "      <td>18766300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>25.790001</td>\n",
       "      <td>30.42</td>\n",
       "      <td>23.299999</td>\n",
       "      <td>23.830000</td>\n",
       "      <td>23.830000</td>\n",
       "      <td>17187100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.92</td>\n",
       "      <td>20.270000</td>\n",
       "      <td>21.959999</td>\n",
       "      <td>21.959999</td>\n",
       "      <td>8218800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-07-02</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.10</td>\n",
       "      <td>18.709999</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>5139800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-06</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.00</td>\n",
       "      <td>15.830000</td>\n",
       "      <td>16.110001</td>\n",
       "      <td>16.110001</td>\n",
       "      <td>6866900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open   High        Low      Close  Adj Close    Volume\n",
       "0  2010-06-29  19.000000  25.00  17.540001  23.889999  23.889999  18766300\n",
       "1  2010-06-30  25.790001  30.42  23.299999  23.830000  23.830000  17187100\n",
       "2  2010-07-01  25.000000  25.92  20.270000  21.959999  21.959999   8218800\n",
       "3  2010-07-02  23.000000  23.10  18.709999  19.200001  19.200001   5139800\n",
       "4  2010-07-06  20.000000  20.00  15.830000  16.110001  16.110001   6866900"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('TSLA.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Date'],axis=1)\n",
    "y = df[\"Close\"]\n",
    "# y = np.log(y)\n",
    "X = df.drop([\"Close\",\"Adj Close\"], axis=1)\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "y = y[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression mdoel closed form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionCloseForm:\n",
    "    def __init__(self):\n",
    "        self.W = None\n",
    "              \n",
    "    def train(self, X_train, y):\n",
    "        X = np.append(np.ones((X_train.shape[0], 1)), X_train , axis=1)\n",
    "        self.W = np.dot((np.linalg.inv(np.dot(X.T,X))), np.dot(X.T,y))\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        X = np.append(np.ones((X_test.shape[0], 1)), X_test , axis=1)\n",
    "        return np.dot(X, self.W)\n",
    "    \n",
    "    def mse_loss(self, pred, real):\n",
    "        diff = pred - real\n",
    "        return np.sum(diff * diff) / diff.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.379434894480742"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RegressionCloseForm()\n",
    "model.train(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "model.mse_loss(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla Linear regression with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_model = linear_model.LinearRegression()\n",
    "regr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE error on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.057920329276165"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train = regr_model.predict(X_train)\n",
    "mean_squared_error(y_train, predictions_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE error on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.379434894417769"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = regr_model.predict(X_test)\n",
    "mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997117604197432"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation of model regression score function. it shows our model works well\n",
    "regr_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare predicted values with real ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-d4bd59b7a70f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcomparison\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Predicted'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Real'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'differnece'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcomparison\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m             \u001b[1;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     return arrays_to_mgr(\n\u001b[1;32m--> 465\u001b[1;33m         \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    466\u001b[0m     )\n\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mindexes\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mraw_lengths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"If using all scalar values, you must pass an index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhave_series\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "comparison = pd.DataFrame({'Predicted':predictions,'Real':y_test, 'differnece':np.abs(predictions - y_test)})\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems that our model worked well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regression model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel:\n",
    "    \n",
    "    def __init__(self, lr, number_of_epochs, regularization=None):\n",
    "        self.m = None # samples\n",
    "        self.n = None # features\n",
    "        self.W = None # weight\n",
    "        self.regularization = regularization # penalty object\n",
    "        self.lr = lr # learning rate\n",
    "        self.epoch = number_of_epochs # iteration\n",
    "        \n",
    "    def __calculate_cost(self, y, y_pred):\n",
    "        cost = (1 / (2 * self.m)) * np.sum(np.square(y_pred-y))\n",
    "        if self.regularization:\n",
    "            return cost + self.regularization(self.W) \n",
    "        return cost\n",
    "    \n",
    "    def __initialize(self, X):\n",
    "        X2 = np.insert(X, 0, 1, axis=1)\n",
    "        self.m, self.n = X2.shape\n",
    "        self.W = np.random.rand(self.n, 1)\n",
    "        return X2\n",
    "    \n",
    "    def __update_weights(self, X, y, y_pred):\n",
    "        dw = np.dot(X.T, (y_pred - y)) / self.m\n",
    "        if self.regularization:\n",
    "            dw += self.regularization.derivation(self.W)\n",
    "        \n",
    "        self.W -= self.lr * dw\n",
    "    \n",
    "    def __feature_scaling(self, data):\n",
    "        data2 = data.copy()\n",
    "        number_of_columns = data.shape[1]\n",
    "        for i in range(number_of_columns):\n",
    "            data2[:,i] = (data2[:,i] - np.mean(data2[:,i])) / np.std(data2[:,i])\n",
    "        return data2\n",
    "        \n",
    "    def fit(self, X_train, y_train, logging=True):\n",
    "        if isinstance(X_train, pd.core.frame.DataFrame):\n",
    "            X_train = X_train.to_numpy()\n",
    "        if isinstance(y_train, pd.core.frame.DataFrame):\n",
    "            y_train = y_train.to_numpy()\n",
    "        X = self.__feature_scaling(X_train)\n",
    "        \n",
    "        X = self.__initialize(X)\n",
    "        y = y_train.reshape(self.m, -1)\n",
    "        for e in range(1, self.epoch+1):\n",
    "            y_pred = np.dot(X, self.W)\n",
    "            cost = self.__calculate_cost(y, y_pred)\n",
    "            self.__update_weights(X, y, y_pred)\n",
    "            if logging and e % 2000 == 0:\n",
    "                print(f\"The Cost in iteration {e}-----> {cost} :)\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        if isinstance(X_test, pd.core.frame.DataFrame):\n",
    "            X_test = X_test.to_numpy()\n",
    "        X_test2 = self.__feature_scaling(X_test)\n",
    "        X_test2 = np.insert(X_test2, 0 , 1, axis= 1)\n",
    "        return np.dot(X_test2, self.W) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(pred, real):\n",
    "    diff = pred - real\n",
    "    return np.sum(diff * diff) / diff.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np = X.to_numpy()\n",
    "y_np = y.to_numpy()\n",
    "y_np = y_np[:, np.newaxis]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_np, y_np, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cost in iteration 2000-----> 0.04589490859013787 :)\n",
      "The Cost in iteration 4000-----> 0.04554232908576736 :)\n",
      "The Cost in iteration 6000-----> 0.04524676010483242 :)\n",
      "The Cost in iteration 8000-----> 0.044998605425820626 :)\n",
      "The Cost in iteration 10000-----> 0.044789941386980524 :)\n",
      "The Cost in iteration 12000-----> 0.04461421702662265 :)\n",
      "The Cost in iteration 14000-----> 0.04446600915630515 :)\n",
      "The Cost in iteration 16000-----> 0.044340822143004326 :)\n",
      "The Cost in iteration 18000-----> 0.04423492410067521 :)\n",
      "The Cost in iteration 20000-----> 0.04414521275089746 :)\n",
      "The Cost in iteration 22000-----> 0.04406910547618604 :)\n",
      "The Cost in iteration 24000-----> 0.04400444911430748 :)\n",
      "The Cost in iteration 26000-----> 0.043949445873101345 :)\n",
      "The Cost in iteration 28000-----> 0.0439025924196812 :)\n",
      "The Cost in iteration 30000-----> 0.0438626297452644 :)\n",
      "The Cost in iteration 32000-----> 0.043828501851354604 :)\n",
      "The Cost in iteration 34000-----> 0.04379932166407815 :)\n",
      "The Cost in iteration 36000-----> 0.04377434287694058 :)\n",
      "The Cost in iteration 38000-----> 0.043752936660901624 :)\n",
      "The Cost in iteration 40000-----> 0.04373457237481593 :)\n",
      "The Cost in iteration 42000-----> 0.04371880156733319 :)\n",
      "The Cost in iteration 44000-----> 0.04370524469008621 :)\n",
      "The Cost in iteration 46000-----> 0.04369358004692333 :)\n",
      "The Cost in iteration 48000-----> 0.04368353458952085 :)\n",
      "The Cost in iteration 50000-----> 0.043674876239562566 :)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10217180558702735"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_model_custom = RegressionModel(lr=0.1, number_of_epochs=50000)\n",
    "reg_model_custom.fit(X_train, y_train)\n",
    "predictions = reg_model_custom.predict(X_test)\n",
    "mse_loss(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:16<00:00, 13.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best learning rate: 0.0005\n",
      "best loss: 0.101274852647318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_loss = np.inf\n",
    "best_lr = None\n",
    "lr_list = [1e-4,5e-4,1e-3,5e-3,1e-2,5e-2,8e-2,1e-1,2e-1,5e-1]\n",
    "for lr in tqdm.tqdm(lr_list):\n",
    "    reg_model_custom = RegressionModel(lr=lr, number_of_epochs=50000)\n",
    "    reg_model_custom.fit(X_train, y_train, logging=False)\n",
    "    predictions = reg_model_custom.predict(X_test)\n",
    "    loss = mse_loss(y_test, predictions)\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_lr = lr\n",
    "print(f'best learning rate: {best_lr}')\n",
    "print(f'best loss: {best_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElasticPenalty:\n",
    "    \n",
    "    def __init__(self, l = 0.1, l_ratio = 0.5):\n",
    "        self.l = l \n",
    "        self.l_ratio = l_ratio\n",
    "\n",
    "    def __call__(self, w):\n",
    "        l1_contribution = self.l_ratio * self.l * np.sum(np.abs(w))\n",
    "        l2_contribution = (1 - self.l_ratio) * self.l * 0.5 * np.sum(np.square(w))\n",
    "        return (l1_contribution + l2_contribution)\n",
    "\n",
    "    def derivation(self, w):\n",
    "        l1_derivation = self.l * self.l_ratio * np.sign(w)\n",
    "        l2_derivation = self.l * (1 - self.l_ratio) * w\n",
    "        return (l1_derivation + l2_derivation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LassoRegression(RegressionModel):\n",
    "        def __init__(self, lr, number_of_epochs, l):\n",
    "            regularization = ElasticPenalty(l, l_ratio=1) # penalty object\n",
    "            super().__init__(lr, number_of_epochs, regularization)\n",
    "\n",
    "            \n",
    "class RidgeRegression(RegressionModel):\n",
    "        def __init__(self, lr, number_of_epochs, l):\n",
    "            regularization = ElasticPenalty(l, l_ratio=0) # penalty object\n",
    "            super().__init__(lr, number_of_epochs, regularization)\n",
    "\n",
    "            \n",
    "class ElasticNet(RegressionModel):\n",
    "        def __init__(self, lr, number_of_epochs, l = 0.1, l_ratio = 0.5):\n",
    "            regularization = ElasticPenalty(l, l_ratio) # penalty object\n",
    "            super().__init__(lr, number_of_epochs, regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cost in iteration 2000-----> 7.791783691256395 :)\n",
      "The Cost in iteration 4000-----> 5.424198712932369 :)\n",
      "The Cost in iteration 6000-----> 3.8395069404799345 :)\n",
      "The Cost in iteration 8000-----> 2.7776504581928974 :)\n",
      "The Cost in iteration 10000-----> 2.0660203276560054 :)\n",
      "The Cost in iteration 12000-----> 1.5890591901327564 :)\n",
      "The Cost in iteration 14000-----> 1.2693642225047124 :)\n",
      "The Cost in iteration 16000-----> 1.0550731317102002 :)\n",
      "The Cost in iteration 18000-----> 0.9114302474039813 :)\n",
      "The Cost in iteration 20000-----> 0.8151425286432754 :)\n",
      "The Cost in iteration 22000-----> 0.7505976536876771 :)\n",
      "The Cost in iteration 24000-----> 0.7073307486014986 :)\n",
      "The Cost in iteration 26000-----> 0.67832707783375 :)\n",
      "The Cost in iteration 28000-----> 0.6588845209965954 :)\n",
      "The Cost in iteration 30000-----> 0.6458511291475699 :)\n",
      "The Cost in iteration 32000-----> 0.6371140611017161 :)\n",
      "The Cost in iteration 34000-----> 0.6312570123964708 :)\n",
      "The Cost in iteration 36000-----> 0.6273305844689979 :)\n",
      "The Cost in iteration 38000-----> 0.6246983586694601 :)\n",
      "The Cost in iteration 40000-----> 0.6229337163050642 :)\n",
      "The Cost in iteration 42000-----> 0.6217506746224282 :)\n",
      "The Cost in iteration 44000-----> 0.6209575243318295 :)\n",
      "The Cost in iteration 46000-----> 0.6204261140411267 :)\n",
      "The Cost in iteration 48000-----> 0.6200701642288987 :)\n",
      "The Cost in iteration 50000-----> 0.6198315748263106 :)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12577833002572614"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model = LassoRegression(lr=1e-4, number_of_epochs=50000, l = 0.1)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "predictions = lasso_model.predict(X_test)\n",
    "mse_loss(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cost in iteration 2000-----> 5.408759168299904 :)\n",
      "The Cost in iteration 4000-----> 3.8870394845944864 :)\n",
      "The Cost in iteration 6000-----> 2.91148193623711 :)\n",
      "The Cost in iteration 8000-----> 2.2841643381393286 :)\n",
      "The Cost in iteration 10000-----> 1.8802293142646904 :)\n",
      "The Cost in iteration 12000-----> 1.619935730901354 :)\n",
      "The Cost in iteration 14000-----> 1.452100246260512 :)\n",
      "The Cost in iteration 16000-----> 1.3438034545040725 :)\n",
      "The Cost in iteration 18000-----> 1.2738554921107974 :)\n",
      "The Cost in iteration 20000-----> 1.2286121638752112 :)\n",
      "The Cost in iteration 22000-----> 1.199286706231999 :)\n",
      "The Cost in iteration 24000-----> 1.1802201123589788 :)\n",
      "The Cost in iteration 26000-----> 1.167767595053518 :)\n",
      "The Cost in iteration 28000-----> 1.159581548665687 :)\n",
      "The Cost in iteration 30000-----> 1.1541497864651045 :)\n",
      "The Cost in iteration 32000-----> 1.150498160987518 :)\n",
      "The Cost in iteration 34000-----> 1.1479990456546894 :)\n",
      "The Cost in iteration 36000-----> 1.146247992231338 :)\n",
      "The Cost in iteration 38000-----> 1.1449842948268514 :)\n",
      "The Cost in iteration 40000-----> 1.1440398307082456 :)\n",
      "The Cost in iteration 42000-----> 1.1433061120729744 :)\n",
      "The Cost in iteration 44000-----> 1.142713066149026 :)\n",
      "The Cost in iteration 46000-----> 1.1422153686532517 :)\n",
      "The Cost in iteration 48000-----> 1.1417836418252743 :)\n",
      "The Cost in iteration 50000-----> 1.14139878539287 :)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2925392150252702"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model = RidgeRegression(lr=1e-4, number_of_epochs=50000, l = 0.1)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "predictions = ridge_model.predict(X_test)\n",
    "mse_loss(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [02:50<00:00, 15.52s/it]\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for i in tqdm.tqdm(range(11)):\n",
    "    parameters = {\n",
    "        \"l_ratio\" : i * 0.1,\n",
    "        \"l\" : 0.1,\n",
    "        \"lr\" : 1e-4,\n",
    "        \"number_of_epochs\" : 50000\n",
    "    }\n",
    "    model = ElasticNet(**parameters)\n",
    "    model.fit(X_train, y_train, logging=False)\n",
    "    predictions = model.predict(X_test)   \n",
    "    losses.append(mse_loss(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [i * 0.1 for i in range(11)]\n",
    "y = losses\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('l ratio')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
