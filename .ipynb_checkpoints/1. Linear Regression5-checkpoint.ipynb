{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font face=\"Times New Roman\" size=5><div dir=ltr align=center>\n",
    "<font color=blue size=8>\n",
    "    Introduction to Machine Learning <br>\n",
    "<font color=red size=5>\n",
    "    Sharif University of Technology - Computer Engineering Department <br>\n",
    "    Fall 2022<br> <br>\n",
    "<font color=black size=6>\n",
    "    Homework 2: Practical - Linear Regression\n",
    "    </div>\n",
    "<br><br>\n",
    "<font size=4>\n",
    "   **Name**: Mohammad Mahdi<br>\n",
    "   **Student ID**: 98105557<br> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Times New Roman\" size=4><div dir=ltr>\n",
    "# Problem 1: Linear Regression Model (40 + 30 optional points)\n",
    "According to <a href=\"https://github.com/asharifiz/Introduction_to_Machine_Learning/blob/main/Jupyter_Notebooks/Chapter_02_Classical_Models/Linear%20regression.ipynb\"><font face=\"Roboto\">Linear Regression Notebook</font></a>, train a linear regression model on an arbitrary dataset. Explain your chosen dataset and split your data into train and test sets, then predict values for the test set using your trained model. Try to find the best hyperparameters for your model. (Using Lasso Regression, Ridge Regression or Elastic Net and comparing them will have extra optional points)\n",
    "<br> Explain each step of your workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mahdi\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading dataset\n",
    "This dataset is Tesla's stock from 2010 to 2020. it has some columns of opening price or highest and lowest price of the day. we try to predict closing/the last price of the stock based on the other features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-06-29</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>25.00</td>\n",
       "      <td>17.540001</td>\n",
       "      <td>23.889999</td>\n",
       "      <td>23.889999</td>\n",
       "      <td>18766300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>25.790001</td>\n",
       "      <td>30.42</td>\n",
       "      <td>23.299999</td>\n",
       "      <td>23.830000</td>\n",
       "      <td>23.830000</td>\n",
       "      <td>17187100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.92</td>\n",
       "      <td>20.270000</td>\n",
       "      <td>21.959999</td>\n",
       "      <td>21.959999</td>\n",
       "      <td>8218800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-07-02</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.10</td>\n",
       "      <td>18.709999</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>5139800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-06</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.00</td>\n",
       "      <td>15.830000</td>\n",
       "      <td>16.110001</td>\n",
       "      <td>16.110001</td>\n",
       "      <td>6866900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open   High        Low      Close  Adj Close    Volume\n",
       "0  2010-06-29  19.000000  25.00  17.540001  23.889999  23.889999  18766300\n",
       "1  2010-06-30  25.790001  30.42  23.299999  23.830000  23.830000  17187100\n",
       "2  2010-07-01  25.000000  25.92  20.270000  21.959999  21.959999   8218800\n",
       "3  2010-07-02  23.000000  23.10  18.709999  19.200001  19.200001   5139800\n",
       "4  2010-07-06  20.000000  20.00  15.830000  16.110001  16.110001   6866900"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('TSLA.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Date'],axis=1)\n",
    "y = df[\"Close\"]\n",
    "# y = np.log(y)\n",
    "X = df.drop([\"Close\",\"Adj Close\"], axis=1)\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "y = y[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression mdoel closed form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionCloseForm:\n",
    "    def __init__(self):\n",
    "        self.W = None\n",
    "              \n",
    "    def train(self, X_train, y):\n",
    "        X = np.append(np.ones((X_train.shape[0], 1)), X_train , axis=1)\n",
    "        self.W = np.dot((np.linalg.inv(np.dot(X.T,X))), np.dot(X.T,y))\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        X = np.append(np.ones((X_test.shape[0], 1)), X_test , axis=1)\n",
    "        return np.dot(X, self.W)\n",
    "    \n",
    "    def mse_loss(self, pred, real):\n",
    "        diff = pred - real\n",
    "        return np.sum(diff * diff) / diff.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.379434894480742"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RegressionCloseForm()\n",
    "model.train(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "model.mse_loss(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla Linear regression with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_model = linear_model.LinearRegression()\n",
    "regr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE error on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.057920329276165"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train = regr_model.predict(X_train)\n",
    "mean_squared_error(y_train, predictions_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE error on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.379434894417769"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = regr_model.predict(X_test)\n",
    "mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997117604197432"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation of model regression score function. it shows our model works well\n",
    "regr_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare predicted values with real ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Real</th>\n",
       "      <th>differnece</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.442062</td>\n",
       "      <td>31.490000</td>\n",
       "      <td>0.047938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.529889</td>\n",
       "      <td>24.650000</td>\n",
       "      <td>0.120111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>278.905101</td>\n",
       "      <td>279.760010</td>\n",
       "      <td>0.854909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>330.673522</td>\n",
       "      <td>328.200012</td>\n",
       "      <td>2.473510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>262.081422</td>\n",
       "      <td>259.320007</td>\n",
       "      <td>2.761415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>174.974500</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>4.025500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>254.608833</td>\n",
       "      <td>251.860001</td>\n",
       "      <td>2.748832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>24.919015</td>\n",
       "      <td>25.059999</td>\n",
       "      <td>0.140984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>341.245531</td>\n",
       "      <td>345.660004</td>\n",
       "      <td>4.414473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>183.127280</td>\n",
       "      <td>183.929993</td>\n",
       "      <td>0.802713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>484 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Predicted        Real  differnece\n",
       "0     31.442062   31.490000    0.047938\n",
       "1     24.529889   24.650000    0.120111\n",
       "2    278.905101  279.760010    0.854909\n",
       "3    330.673522  328.200012    2.473510\n",
       "4    262.081422  259.320007    2.761415\n",
       "..          ...         ...         ...\n",
       "479  174.974500  179.000000    4.025500\n",
       "480  254.608833  251.860001    2.748832\n",
       "481   24.919015   25.059999    0.140984\n",
       "482  341.245531  345.660004    4.414473\n",
       "483  183.127280  183.929993    0.802713\n",
       "\n",
       "[484 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison = pd.DataFrame({'Predicted':predictions.flatten(),'Real':y_test.flatten(), 'differnece':np.abs(predictions - y_test).flatten()})\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems that our model worked well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.489151213935677"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticnet_model = ElasticNet(alpha=0.1, l1_ratio=1, max_iter=10000)\n",
    "elasticnet_model.fit(X_train, y_train)\n",
    "predictions = elasticnet_model.predict(X_test)\n",
    "mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regression model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel:\n",
    "    \n",
    "    def __init__(self, lr, number_of_epochs, regularization=None):\n",
    "        self.m = None # samples\n",
    "        self.n = None # features\n",
    "        self.W = None # weight\n",
    "        self.regularization = regularization # penalty object\n",
    "        self.lr = lr # learning rate\n",
    "        self.epoch = number_of_epochs # iteration\n",
    "        self.train_mean = None\n",
    "        self.train_std = None\n",
    "        \n",
    "    def __calculate_cost(self, y, y_pred):\n",
    "        cost = (1 / (2 * self.m)) * np.sum(np.square(y_pred-y))\n",
    "        if self.regularization:\n",
    "            return cost + self.regularization(self.W) \n",
    "        return cost\n",
    "    \n",
    "    def __initialize(self, X):\n",
    "        X2 = np.insert(X, 0, 1, axis=1)\n",
    "        self.m, self.n = X2.shape\n",
    "        self.W = np.random.rand(self.n, 1)\n",
    "        return X2\n",
    "    \n",
    "    def __update_weights(self, X, y, y_pred):\n",
    "        dw = np.dot(X.T, (y_pred - y)) / self.m\n",
    "        if self.regularization:\n",
    "            dw += self.regularization.derivation(self.W)\n",
    "        \n",
    "        self.W -= self.lr * dw\n",
    "    \n",
    "    def __feature_scaling(self, data, is_training = False):\n",
    "        data2 = data.copy()\n",
    "        number_of_columns = data.shape[1]\n",
    "        if is_training:\n",
    "            self.train_mean = [0] * number_of_columns\n",
    "            self.train_std = [0] * number_of_columns\n",
    "        for i in range(number_of_columns):\n",
    "            if is_training:\n",
    "                self.train_mean[i] = np.mean(data2[:,i])\n",
    "                self.train_std[i] = np.std(data2[:,i])\n",
    "            data2[:,i] = (data2[:,i] - self.train_mean[i]) / self.train_std[i]\n",
    "        return data2\n",
    "        \n",
    "    def fit(self, X_train, y_train, logging=True):\n",
    "        if isinstance(X_train, pd.core.frame.DataFrame):\n",
    "            X_train = X_train.to_numpy()\n",
    "        if isinstance(y_train, pd.core.frame.DataFrame):\n",
    "            y_train = y_train.to_numpy()\n",
    "        X = self.__feature_scaling(X_train, is_training=True)\n",
    "        \n",
    "        X = self.__initialize(X)\n",
    "        y = y_train.reshape(self.m, -1)\n",
    "        for e in range(1, self.epoch+1):\n",
    "            y_pred = np.dot(X, self.W)\n",
    "            cost = self.__calculate_cost(y, y_pred)\n",
    "            self.__update_weights(X, y, y_pred)\n",
    "            if logging and e % 10000 == 0:\n",
    "                print(f\"The Cost in iteration {e}-----> {cost} :)\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        if isinstance(X_test, pd.core.frame.DataFrame):\n",
    "            X_test = X_test.to_numpy()\n",
    "        X_test2 = self.__feature_scaling(X_test)\n",
    "        X_test2 = np.insert(X_test2, 0 , 1, axis= 1)\n",
    "        return np.dot(X_test2, self.W) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(pred, real):\n",
    "    diff = pred - real\n",
    "    return np.sum(diff * diff) / diff.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cost in iteration 10000-----> 3.877932076519058 :)\n",
      "The Cost in iteration 20000-----> 2.699599640743386 :)\n",
      "The Cost in iteration 30000-----> 2.2775014426424525 :)\n",
      "The Cost in iteration 40000-----> 2.123604911381484 :)\n",
      "The Cost in iteration 50000-----> 2.0661885075676976 :)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.51367396578572"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_model_custom = RegressionModel(lr=0.1, number_of_epochs=50000)\n",
    "reg_model_custom.fit(X_train, y_train)\n",
    "predictions = reg_model_custom.predict(X_test)\n",
    "mse_loss(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:26<00:00, 14.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best learning rate: 0.5\n",
      "best loss: 4.379554516403111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_loss = np.inf\n",
    "best_lr = None\n",
    "lr_list = [1e-4,5e-4,1e-3,5e-3,1e-2,5e-2,8e-2,1e-1,2e-1,5e-1]\n",
    "for lr in tqdm.tqdm(lr_list):\n",
    "    reg_model_custom = RegressionModel(lr=lr, number_of_epochs=50000)\n",
    "    reg_model_custom.fit(X_train, y_train, logging=False)\n",
    "    predictions = reg_model_custom.predict(X_test)\n",
    "    loss = mse_loss(y_test, predictions)\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_lr = lr\n",
    "print(f'best learning rate: {best_lr}')\n",
    "print(f'best loss: {best_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElasticPenalty:\n",
    "    \n",
    "    def __init__(self, l = 0.1, l_ratio = 0.5):\n",
    "        self.l = l \n",
    "        self.l_ratio = l_ratio\n",
    "\n",
    "    def __call__(self, w):\n",
    "        l1_contribution = self.l_ratio * self.l * np.sum(np.abs(w))\n",
    "        l2_contribution = (1 - self.l_ratio) * self.l * 0.5 * np.sum(np.square(w))\n",
    "        return l1_contribution + l2_contribution\n",
    "\n",
    "    def derivation(self, w):\n",
    "        l1_derivation = self.l * self.l_ratio * np.sign(w)\n",
    "        l2_derivation = self.l * (1 - self.l_ratio) * w\n",
    "        return l1_derivation + l2_derivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LassoRegression(RegressionModel):\n",
    "        def __init__(self, lr, number_of_epochs, l):\n",
    "            regularization = ElasticPenalty(l, l_ratio=1) # penalty object\n",
    "            super().__init__(lr, number_of_epochs, regularization)\n",
    "\n",
    "            \n",
    "class RidgeRegression(RegressionModel):\n",
    "        def __init__(self, lr, number_of_epochs, l):\n",
    "            regularization = ElasticPenalty(l, l_ratio=0) # penalty object\n",
    "            super().__init__(lr, number_of_epochs, regularization)\n",
    "\n",
    "            \n",
    "class ElasticNet(RegressionModel):\n",
    "        def __init__(self, lr, number_of_epochs, l = 0.1, l_ratio = 0.5):\n",
    "            regularization = ElasticPenalty(l, l_ratio) # penalty object\n",
    "            super().__init__(lr, number_of_epochs, regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cost in iteration 10000-----> 35.537325895000485 :)\n",
      "The Cost in iteration 20000-----> 34.61455404931392 :)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.862348545742582"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model = LassoRegression(lr=5e-2, number_of_epochs=25000, l = 0.1)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "predictions = lasso_model.predict(X_test)\n",
    "mse_loss(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cost in iteration 10000-----> 1807.4499366199148 :)\n",
      "The Cost in iteration 20000-----> 1807.4499366199148 :)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "313.99776818038384"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model = RidgeRegression(lr=5e-2, number_of_epochs=25000, l = 0.1)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "predictions = ridge_model.predict(X_test)\n",
    "mse_loss(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:31<00:00,  2.89s/it]\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for i in tqdm.tqdm(range(11)):\n",
    "    parameters = {\n",
    "        \"l_ratio\" : i * 0.1,\n",
    "        \"l\" : 0.1,\n",
    "        \"lr\" : 5e-2,\n",
    "        \"number_of_epochs\" : 10000\n",
    "    }\n",
    "    model = ElasticNet(**parameters)\n",
    "    model.fit(X_train, y_train, logging=False)\n",
    "    predictions = model.predict(X_test)   \n",
    "    losses.append(mse_loss(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [i * 0.1 for i in range(11)]\n",
    "y = losses\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('l ratio')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
