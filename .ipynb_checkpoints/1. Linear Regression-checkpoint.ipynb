{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font face=\"Times New Roman\" size=5><div dir=ltr align=center>\n",
    "<font color=blue size=8>\n",
    "    Introduction to Machine Learning <br>\n",
    "<font color=red size=5>\n",
    "    Sharif University of Technology - Computer Engineering Department <br>\n",
    "    Fall 2022<br> <br>\n",
    "<font color=black size=6>\n",
    "    Homework 2: Practical - Linear Regression\n",
    "    </div>\n",
    "<br><br>\n",
    "<font size=4>\n",
    "   **Name**: Mohammad Mahdi<br>\n",
    "   **Student ID**: 98105557<br> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Times New Roman\" size=4><div dir=ltr>\n",
    "# Problem 1: Linear Regression Model (40 + 30 optional points)\n",
    "According to <a href=\"https://github.com/asharifiz/Introduction_to_Machine_Learning/blob/main/Jupyter_Notebooks/Chapter_02_Classical_Models/Linear%20regression.ipynb\"><font face=\"Roboto\">Linear Regression Notebook</font></a>, train a linear regression model on an arbitrary dataset. Explain your chosen dataset and split your data into train and test sets, then predict values for the test set using your trained model. Try to find the best hyperparameters for your model. (Using Lasso Regression, Ridge Regression or Elastic Net and comparing them will have extra optional points)\n",
    "<br> Explain each step of your workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading dataset\n",
    "This dataset is Tesla's stock from 2010 to 2020. it has some columns of opening price or highest and lowest price of the day. we try to predict closing/the last price of the stock based on the other features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-06-29</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>25.00</td>\n",
       "      <td>17.540001</td>\n",
       "      <td>23.889999</td>\n",
       "      <td>23.889999</td>\n",
       "      <td>18766300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>25.790001</td>\n",
       "      <td>30.42</td>\n",
       "      <td>23.299999</td>\n",
       "      <td>23.830000</td>\n",
       "      <td>23.830000</td>\n",
       "      <td>17187100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.92</td>\n",
       "      <td>20.270000</td>\n",
       "      <td>21.959999</td>\n",
       "      <td>21.959999</td>\n",
       "      <td>8218800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-07-02</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.10</td>\n",
       "      <td>18.709999</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>5139800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-06</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.00</td>\n",
       "      <td>15.830000</td>\n",
       "      <td>16.110001</td>\n",
       "      <td>16.110001</td>\n",
       "      <td>6866900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open   High        Low      Close  Adj Close    Volume\n",
       "0  2010-06-29  19.000000  25.00  17.540001  23.889999  23.889999  18766300\n",
       "1  2010-06-30  25.790001  30.42  23.299999  23.830000  23.830000  17187100\n",
       "2  2010-07-01  25.000000  25.92  20.270000  21.959999  21.959999   8218800\n",
       "3  2010-07-02  23.000000  23.10  18.709999  19.200001  19.200001   5139800\n",
       "4  2010-07-06  20.000000  20.00  15.830000  16.110001  16.110001   6866900"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('TSLA.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create proper X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Date'],axis=1)\n",
    "y = df[\"Close\"]\n",
    "X = df.drop([\"Close\",\"Adj Close\"], axis=1)\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "y = y[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset to train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For extra point as told in quera, we write our custom grain test split that performs like scikit-learn function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_size=0.2, shuffle=True, random_state=0):\n",
    "    np.random.seed(random_state)\n",
    "    data_len = len(X)\n",
    "    new_x = X.copy()\n",
    "    new_y = y.copy()\n",
    "    if shuffle:\n",
    "        p = np.random.permutation(data_len)\n",
    "        new_x, new_y = X[p], y[p]\n",
    "    len_test = int(np.ceil(test_size * data_len))\n",
    "    return new_x[len_test:], new_x[:len_test], new_y[len_test:], new_y[:len_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1932\n",
      "484\n",
      "1932\n",
      "484\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression mdoel closed form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionCloseForm:\n",
    "    def __init__(self):\n",
    "        self.W = None\n",
    "              \n",
    "    def train(self, X_train, y):\n",
    "        X = np.append(np.ones((X_train.shape[0], 1)), X_train , axis=1)\n",
    "        self.W = np.dot((np.linalg.inv(np.dot(X.T,X))), np.dot(X.T,y))\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        X = np.append(np.ones((X_test.shape[0], 1)), X_test , axis=1)\n",
    "        return np.dot(X, self.W)\n",
    "    \n",
    "    def mse_loss(self, pred, real):\n",
    "        diff = pred - real\n",
    "        return np.sum(diff * diff) / diff.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.379434894480742"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RegressionCloseForm()\n",
    "model.train(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "model.mse_loss(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla Linear regression with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_model = linear_model.LinearRegression()\n",
    "regr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.057920329276165"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train = regr_model.predict(X_train)\n",
    "mean_squared_error(y_train, predictions_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.379434894417769"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = regr_model.predict(X_test)\n",
    "mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997117604197432"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation of model regression score function. it shows our model works well\n",
    "regr_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare predicted values with real ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Real</th>\n",
       "      <th>differnece</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.442062</td>\n",
       "      <td>31.490000</td>\n",
       "      <td>0.047938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.529889</td>\n",
       "      <td>24.650000</td>\n",
       "      <td>0.120111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>278.905101</td>\n",
       "      <td>279.760010</td>\n",
       "      <td>0.854909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>330.673522</td>\n",
       "      <td>328.200012</td>\n",
       "      <td>2.473510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>262.081422</td>\n",
       "      <td>259.320007</td>\n",
       "      <td>2.761415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Predicted        Real  differnece\n",
       "0   31.442062   31.490000    0.047938\n",
       "1   24.529889   24.650000    0.120111\n",
       "2  278.905101  279.760010    0.854909\n",
       "3  330.673522  328.200012    2.473510\n",
       "4  262.081422  259.320007    2.761415"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison = pd.DataFrame({'Predicted':predictions.flatten(),'Real':y_test.flatten(), 'differnece':np.abs(predictions - y_test).flatten()})\n",
    "comparison.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems that our model worked well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElasticNet with sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set l1_ratio to 1 to have lasso model. (As you will see at the end of the notebook lasso works better on our dataset than ridge or other combinations.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.489151213935677"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticnet_model = ElasticNet(alpha=0.1, l1_ratio=1, max_iter=10000)\n",
    "elasticnet_model.fit(X_train, y_train)\n",
    "predictions = elasticnet_model.predict(X_test)\n",
    "mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems vanilla model performs better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regression model from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create our regression model from scratch. It works with gradiant descent and you can  pass differnet regularization term to it. So we can create differnet models like vanila linear regression or lasso or ridge or elasticNet with this class. We do some feature scaling in our model, in order to performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel:\n",
    "    \n",
    "    def __init__(self, lr, number_of_epochs, regularization=None):\n",
    "        self.m = None # samples\n",
    "        self.n = None # features\n",
    "        self.W = None # weight\n",
    "        self.regularization = regularization # penalty object\n",
    "        self.lr = lr # learning rate\n",
    "        self.epoch = number_of_epochs # iteration\n",
    "        self.train_mean = None\n",
    "        self.train_std = None\n",
    "        \n",
    "    def __calculate_cost(self, y, y_pred):\n",
    "        cost = (1 / (2 * self.m)) * np.sum(np.square(y_pred-y))\n",
    "        if self.regularization:\n",
    "            return cost + self.regularization(self.W) \n",
    "        return cost\n",
    "    \n",
    "    def __initialize(self, X):\n",
    "        X2 = np.insert(X, 0, 1, axis=1)\n",
    "        self.m, self.n = X2.shape\n",
    "        self.W = np.random.rand(self.n, 1)\n",
    "        return X2\n",
    "    \n",
    "    def __update_weights(self, X, y, y_pred):\n",
    "        dw = np.dot(X.T, (y_pred - y)) / self.m\n",
    "        if self.regularization:\n",
    "            dw += self.regularization.derivation(self.W)\n",
    "        \n",
    "        self.W -= self.lr * dw\n",
    "    \n",
    "    def __feature_scaling(self, data, is_training = False):\n",
    "        data2 = data.copy()\n",
    "        number_of_columns = data.shape[1]\n",
    "        if is_training:\n",
    "            self.train_mean = [0] * number_of_columns\n",
    "            self.train_std = [0] * number_of_columns\n",
    "        for i in range(number_of_columns):\n",
    "            if is_training:\n",
    "                self.train_mean[i] = np.mean(data2[:,i])\n",
    "                self.train_std[i] = np.std(data2[:,i])\n",
    "            data2[:,i] = (data2[:,i] - self.train_mean[i]) / self.train_std[i]\n",
    "        return data2\n",
    "        \n",
    "    def fit(self, X_train, y_train, logging=True):\n",
    "        if isinstance(X_train, pd.core.frame.DataFrame):\n",
    "            X_train = X_train.to_numpy()\n",
    "        if isinstance(y_train, pd.core.frame.DataFrame):\n",
    "            y_train = y_train.to_numpy()\n",
    "        X = self.__feature_scaling(X_train, is_training=True)\n",
    "        \n",
    "        X = self.__initialize(X)\n",
    "        y = y_train.reshape(self.m, -1)\n",
    "        for e in range(1, self.epoch+1):\n",
    "            y_pred = np.dot(X, self.W)\n",
    "            cost = self.__calculate_cost(y, y_pred)\n",
    "            self.__update_weights(X, y, y_pred)\n",
    "            if logging and e % 10000 == 0:\n",
    "                print(f\"The Cost in iteration {e}-----> {cost} :)\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        if isinstance(X_test, pd.core.frame.DataFrame):\n",
    "            X_test = X_test.to_numpy()\n",
    "        X_test2 = self.__feature_scaling(X_test)\n",
    "        X_test2 = np.insert(X_test2, 0 , 1, axis= 1)\n",
    "        return np.dot(X_test2, self.W) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(pred, real):\n",
    "    diff = pred - real\n",
    "    return np.sum(diff * diff) / diff.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cost in iteration 10000-----> 3.8673315836782898 :)\n",
      "The Cost in iteration 20000-----> 2.696549278027988 :)\n",
      "The Cost in iteration 30000-----> 2.2767513484952184 :)\n",
      "The Cost in iteration 40000-----> 2.1234975016133197 :)\n",
      "The Cost in iteration 50000-----> 2.066227529734436 :)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.514885749886817"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_model_custom = RegressionModel(lr=0.1, number_of_epochs=50000)\n",
    "reg_model_custom.fit(X_train, y_train)\n",
    "predictions = reg_model_custom.predict(X_test)\n",
    "mse_loss(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you have seen our mes loss on test set is very close to close to our scikitlearn library model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding best learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit model with different learning rates and picks the best one based on mse loss on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:57<00:00, 17.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best learning rate: 0.5\n",
      "best loss: 4.379553730772162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_loss = np.inf\n",
    "best_lr = None\n",
    "lr_list = [1e-4,5e-4,1e-3,5e-3,1e-2,5e-2,8e-2,1e-1,2e-1,5e-1]\n",
    "for lr in tqdm.tqdm(lr_list):\n",
    "    reg_model_custom = RegressionModel(lr=lr, number_of_epochs=50000)\n",
    "    reg_model_custom.fit(X_train, y_train, logging=False)\n",
    "    predictions = reg_model_custom.predict(X_test)\n",
    "    loss = mse_loss(y_test, predictions)\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_lr = lr\n",
    "print(f'best learning rate: {best_lr}')\n",
    "print(f'best loss: {best_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see vanilla model with this learning rate works very well. Its mse loss is very close to scikitlearn llinear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso regression, Ridge regression, ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define Elastic penalty class as an regularization term. We create differenet lasso and ridge and elasticNet classes base on differet l_ratio and our Base regression class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElasticPenalty:\n",
    "    \n",
    "    def __init__(self, l = 0.1, l_ratio = 0.5):\n",
    "        self.l = l \n",
    "        self.l_ratio = l_ratio\n",
    "\n",
    "    def __call__(self, w):\n",
    "        l1_contribution = self.l_ratio * self.l * np.sum(np.abs(w))\n",
    "        l2_contribution = (1 - self.l_ratio) * self.l * 0.5 * np.sum(np.square(w))\n",
    "        return l1_contribution + l2_contribution\n",
    "\n",
    "    def derivation(self, w):\n",
    "        l1_derivation = self.l * self.l_ratio * np.sign(w)\n",
    "        l2_derivation = self.l * (1 - self.l_ratio) * w\n",
    "        return l1_derivation + l2_derivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LassoRegression(RegressionModel):\n",
    "        def __init__(self, lr, number_of_epochs, l):\n",
    "            regularization = ElasticPenalty(l, l_ratio=1) # penalty object\n",
    "            super().__init__(lr, number_of_epochs, regularization)\n",
    "\n",
    "            \n",
    "class RidgeRegression(RegressionModel):\n",
    "        def __init__(self, lr, number_of_epochs, l):\n",
    "            regularization = ElasticPenalty(l, l_ratio=0) # penalty object\n",
    "            super().__init__(lr, number_of_epochs, regularization)\n",
    "\n",
    "            \n",
    "class ElasticNet(RegressionModel):\n",
    "        def __init__(self, lr, number_of_epochs, l = 0.1, l_ratio = 0.5):\n",
    "            regularization = ElasticPenalty(l, l_ratio) # penalty object\n",
    "            super().__init__(lr, number_of_epochs, regularization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train our lasso regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cost in iteration 10000-----> 35.55808910293076 :)\n",
      "The Cost in iteration 20000-----> 34.61449184556921 :)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.865532347645803"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model = LassoRegression(lr=5e-2, number_of_epochs=25000, l = 0.1)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "predictions = lasso_model.predict(X_test)\n",
    "mse_loss(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see our vanila model performs better than lasso. but they are close."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train our ridge regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cost in iteration 10000-----> 1807.4499366199148 :)\n",
      "The Cost in iteration 20000-----> 1807.4499366199148 :)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "313.99776818038384"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model = RidgeRegression(lr=5e-2, number_of_epochs=25000, l = 0.1)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "predictions = ridge_model.predict(X_test)\n",
    "mse_loss(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see ridge model doesn't work well on our data and this model in not good for our problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElasticNet models with different l_ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train differenet elasticNet models with different l_ratios and see what model performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [03:52<00:00, 21.12s/it]\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for i in tqdm.tqdm(range(11)):\n",
    "    parameters = {\n",
    "        \"l_ratio\" : i * 0.1,\n",
    "        \"l\" : 0.1,\n",
    "        \"lr\" : 5e-2,\n",
    "        \"number_of_epochs\" : 50000\n",
    "    }\n",
    "    model = ElasticNet(**parameters)\n",
    "    model.fit(X_train, y_train, logging=False)\n",
    "    predictions = model.predict(X_test)   \n",
    "    losses.append(mse_loss(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [i * 0.1 for i in range(11)]\n",
    "y = losses\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('l ratio')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see on above plot, lasso regression works better than other elasticNet models and ridge model is the worst one. as l_ratio becomes greater, our loss becomes less and the model with higher l_ratio works better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best hyper parameter for lasso regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see above, lasso regression is better that other elasticNet models. Now we try to find best 'l' hyperparameter that it controls the weights of regularization term and our vanilla loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best l: 0.01\n",
      "best loss: 5.941207731374518\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "best_loss = np.inf\n",
    "best_l = None\n",
    "ls = list(0.01 * i for i in range(1,10)) + list(0.1 * i for i in range(1,10))\n",
    "for i in ls:\n",
    "    parameters = {\n",
    "        \"l\" : i,\n",
    "        \"lr\" : 5e-2,\n",
    "        \"number_of_epochs\" : 50000\n",
    "    }\n",
    "    model = LassoRegression(**parameters)\n",
    "    model.fit(X_train, y_train, logging=False)\n",
    "    predictions = model.predict(X_test)   \n",
    "    loss = mse_loss(y_test, predictions)\n",
    "    losses.append(loss)\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_l = i\n",
    "\n",
    "print(f'best l: {best_l}')\n",
    "print(f'best loss: {best_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ls, losses)\n",
    "plt.xlabel('l')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, the best l is the smallest one. and the loss is better and close to our best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, we can say that our vanilla model is the best one. Actually it means that overfit does not happened on our problem. and linear regression model is simple for our data. So, adding regularizing term does not help us. The vanilla model works better. and as you see above the smaller the 'l' is in our lasso model (it means lower importance of regularization term), the better loss we have. scikit-learn models works on the same page too and as we see in previous parts, ready vanilla model from scikit-learn performs better than lasso one. So our models from scratch works very well and they are very close to state of the art models in linear regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
