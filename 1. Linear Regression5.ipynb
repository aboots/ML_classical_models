{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font face=\"Times New Roman\" size=5><div dir=ltr align=center>\n",
    "<font color=blue size=8>\n",
    "    Introduction to Machine Learning <br>\n",
    "<font color=red size=5>\n",
    "    Sharif University of Technology - Computer Engineering Department <br>\n",
    "    Fall 2022<br> <br>\n",
    "<font color=black size=6>\n",
    "    Homework 2: Practical - Linear Regression\n",
    "    </div>\n",
    "<br><br>\n",
    "<font size=4>\n",
    "   **Name**: Mohammad Mahdi<br>\n",
    "   **Student ID**: 98105557<br> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Times New Roman\" size=4><div dir=ltr>\n",
    "# Problem 1: Linear Regression Model (40 + 30 optional points)\n",
    "According to <a href=\"https://github.com/asharifiz/Introduction_to_Machine_Learning/blob/main/Jupyter_Notebooks/Chapter_02_Classical_Models/Linear%20regression.ipynb\"><font face=\"Roboto\">Linear Regression Notebook</font></a>, train a linear regression model on an arbitrary dataset. Explain your chosen dataset and split your data into train and test sets, then predict values for the test set using your trained model. Try to find the best hyperparameters for your model. (Using Lasso Regression, Ridge Regression or Elastic Net and comparing them will have extra optional points)\n",
    "<br> Explain each step of your workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading dataset\n",
    "This dataset is Tesla's stock from 2010 to 2020. it has some columns of opening price or highest and lowest price of the day. we try to predict closing/the last price of the stock based on the other features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-06-29</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>25.00</td>\n",
       "      <td>17.540001</td>\n",
       "      <td>23.889999</td>\n",
       "      <td>23.889999</td>\n",
       "      <td>18766300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>25.790001</td>\n",
       "      <td>30.42</td>\n",
       "      <td>23.299999</td>\n",
       "      <td>23.830000</td>\n",
       "      <td>23.830000</td>\n",
       "      <td>17187100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.92</td>\n",
       "      <td>20.270000</td>\n",
       "      <td>21.959999</td>\n",
       "      <td>21.959999</td>\n",
       "      <td>8218800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-07-02</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.10</td>\n",
       "      <td>18.709999</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>5139800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-06</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.00</td>\n",
       "      <td>15.830000</td>\n",
       "      <td>16.110001</td>\n",
       "      <td>16.110001</td>\n",
       "      <td>6866900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open   High        Low      Close  Adj Close    Volume\n",
       "0  2010-06-29  19.000000  25.00  17.540001  23.889999  23.889999  18766300\n",
       "1  2010-06-30  25.790001  30.42  23.299999  23.830000  23.830000  17187100\n",
       "2  2010-07-01  25.000000  25.92  20.270000  21.959999  21.959999   8218800\n",
       "3  2010-07-02  23.000000  23.10  18.709999  19.200001  19.200001   5139800\n",
       "4  2010-07-06  20.000000  20.00  15.830000  16.110001  16.110001   6866900"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('TSLA.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Date'],axis=1)\n",
    "y = df[\"Close\"]\n",
    "# y = np.log(y)\n",
    "X = df.drop([\"Close\",\"Adj Close\", \"Volume\"], axis=1)\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "y = y[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression mdoel closed form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionCloseForm:\n",
    "    def __init__(self):\n",
    "        self.W = None\n",
    "              \n",
    "    def train(self, X_train, y):\n",
    "        X = np.append(np.ones((X_train.shape[0], 1)), X_train , axis=1)\n",
    "        self.W = np.dot((np.linalg.inv(np.dot(X.T,X))), np.dot(X.T,y))\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        X = np.append(np.ones((X_test.shape[0], 1)), X_test , axis=1)\n",
    "        return np.dot(X, self.W)\n",
    "    \n",
    "    def mse_loss(self, pred, real):\n",
    "        diff = pred - real\n",
    "        return np.sum(diff * diff) / diff.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.33599499201486"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RegressionCloseForm()\n",
    "model.train(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "model.mse_loss(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla Linear regression with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_model = linear_model.LinearRegression()\n",
    "regr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE error on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.072263443853506"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train = regr_model.predict(X_train)\n",
    "mean_squared_error(y_train, predictions_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE error on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.335994992006454"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = regr_model.predict(X_test)\n",
    "mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997146194870747"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation of model regression score function. it shows our model works well\n",
    "regr_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare predicted values with real ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Real</th>\n",
       "      <th>differnece</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.401864</td>\n",
       "      <td>31.490000</td>\n",
       "      <td>0.088136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.501496</td>\n",
       "      <td>24.650000</td>\n",
       "      <td>0.148504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>278.907767</td>\n",
       "      <td>279.760010</td>\n",
       "      <td>0.852243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>330.569260</td>\n",
       "      <td>328.200012</td>\n",
       "      <td>2.369248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>262.135069</td>\n",
       "      <td>259.320007</td>\n",
       "      <td>2.815062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>174.848046</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>4.151954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>254.584768</td>\n",
       "      <td>251.860001</td>\n",
       "      <td>2.724767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>24.871589</td>\n",
       "      <td>25.059999</td>\n",
       "      <td>0.188410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>341.160407</td>\n",
       "      <td>345.660004</td>\n",
       "      <td>4.499597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>183.125114</td>\n",
       "      <td>183.929993</td>\n",
       "      <td>0.804879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>484 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Predicted        Real  differnece\n",
       "0     31.401864   31.490000    0.088136\n",
       "1     24.501496   24.650000    0.148504\n",
       "2    278.907767  279.760010    0.852243\n",
       "3    330.569260  328.200012    2.369248\n",
       "4    262.135069  259.320007    2.815062\n",
       "..          ...         ...         ...\n",
       "479  174.848046  179.000000    4.151954\n",
       "480  254.584768  251.860001    2.724767\n",
       "481   24.871589   25.059999    0.188410\n",
       "482  341.160407  345.660004    4.499597\n",
       "483  183.125114  183.929993    0.804879\n",
       "\n",
       "[484 rows x 3 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison = pd.DataFrame({'Predicted':predictions.flatten(),'Real':y_test.flatten(), 'differnece':np.abs(predictions - y_test).flatten()})\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems that our model worked well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.4132143024281705"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticnet_model = ElasticNet(alpha=0.1, l1_ratio=1, max_iter=10000)\n",
    "elasticnet_model.fit(X_train, y_train)\n",
    "predictions = elasticnet_model.predict(X_test)\n",
    "mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regression model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel:\n",
    "    \n",
    "    def __init__(self, lr, number_of_epochs, regularization=None):\n",
    "        self.m = None # samples\n",
    "        self.n = None # features\n",
    "        self.W = None # weight\n",
    "        self.regularization = regularization # penalty object\n",
    "        self.lr = lr # learning rate\n",
    "        self.epoch = number_of_epochs # iteration\n",
    "        self.train_mean = None\n",
    "        self.train_std = None\n",
    "        \n",
    "    def __calculate_cost(self, y, y_pred):\n",
    "        cost = (1 / (2 * self.m)) * np.sum(np.square(y_pred-y))\n",
    "        if self.regularization:\n",
    "            return cost + self.regularization(self.W) \n",
    "        return cost\n",
    "    \n",
    "    def __initialize(self, X):\n",
    "        X2 = np.insert(X, 0, 1, axis=1)\n",
    "        self.m, self.n = X2.shape\n",
    "        self.W = np.random.rand(self.n, 1)\n",
    "        return X2\n",
    "    \n",
    "    def __update_weights(self, X, y, y_pred):\n",
    "        dw = np.dot(X.T, (y_pred - y)) / self.m\n",
    "        if self.regularization:\n",
    "            dw += self.regularization.derivation(self.W)\n",
    "        \n",
    "        self.W -= self.lr * dw\n",
    "    \n",
    "    def __feature_scaling(self, data, is_training = False):\n",
    "        data2 = data.copy()\n",
    "        number_of_columns = data.shape[1]\n",
    "        if is_training:\n",
    "            self.train_mean = [0] * number_of_columns\n",
    "            self.train_std = [0] * number_of_columns\n",
    "        for i in range(number_of_columns):\n",
    "            if is_training:\n",
    "                self.train_mean[i] = np.mean(data2[:,i])\n",
    "                self.train_std[i] = np.std(data2[:,i])\n",
    "            data2[:,i] = (data2[:,i] - self.train_mean[i]) / self.train_std[i]\n",
    "        return data2\n",
    "        \n",
    "    def fit(self, X_train, y_train, logging=True):\n",
    "        if isinstance(X_train, pd.core.frame.DataFrame):\n",
    "            X_train = X_train.to_numpy()\n",
    "        if isinstance(y_train, pd.core.frame.DataFrame):\n",
    "            y_train = y_train.to_numpy()\n",
    "        X = self.__feature_scaling(X_train, is_training=True)\n",
    "        \n",
    "        X = self.__initialize(X)\n",
    "        y = y_train.reshape(self.m, -1)\n",
    "        for e in range(1, self.epoch+1):\n",
    "            y_pred = np.dot(X, self.W)\n",
    "            cost = self.__calculate_cost(y, y_pred)\n",
    "            self.__update_weights(X, y, y_pred)\n",
    "            if logging and e % 10000 == 0:\n",
    "                print(f\"The Cost in iteration {e}-----> {cost} :)\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        if isinstance(X_test, pd.core.frame.DataFrame):\n",
    "            X_test = X_test.to_numpy()\n",
    "        X_test2 = self.__feature_scaling(X_test)\n",
    "        X_test2 = np.insert(X_test2, 0 , 1, axis= 1)\n",
    "        return np.dot(X_test2, self.W) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(pred, real):\n",
    "    diff = pred - real\n",
    "    return np.sum(diff * diff) / diff.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cost in iteration 10000-----> 3.837495970640228 :)\n",
      "The Cost in iteration 20000-----> 2.6985138548146645 :)\n",
      "The Cost in iteration 30000-----> 2.291529583108941 :)\n",
      "The Cost in iteration 40000-----> 2.137841325696809 :)\n",
      "The Cost in iteration 50000-----> 2.0774798198803253 :)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.482488375698887"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_model_custom = RegressionModel(lr=0.1, number_of_epochs=50000)\n",
    "reg_model_custom.fit(X_train, y_train)\n",
    "predictions = reg_model_custom.predict(X_test)\n",
    "mse_loss(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:14<00:00,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best learning rate: 0.5\n",
      "best loss: 4.336010209148474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_loss = np.inf\n",
    "best_lr = None\n",
    "lr_list = [1e-4,5e-4,1e-3,5e-3,1e-2,5e-2,8e-2,1e-1,2e-1,5e-1]\n",
    "for lr in tqdm.tqdm(lr_list):\n",
    "    reg_model_custom = RegressionModel(lr=lr, number_of_epochs=50000)\n",
    "    reg_model_custom.fit(X_train, y_train, logging=False)\n",
    "    predictions = reg_model_custom.predict(X_test)\n",
    "    loss = mse_loss(y_test, predictions)\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_lr = lr\n",
    "print(f'best learning rate: {best_lr}')\n",
    "print(f'best loss: {best_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElasticPenalty:\n",
    "    \n",
    "    def __init__(self, l = 0.1, l_ratio = 0.5):\n",
    "        self.l = l \n",
    "        self.l_ratio = l_ratio\n",
    "\n",
    "    def __call__(self, w):\n",
    "        l1_contribution = self.l_ratio * self.l * np.sum(np.abs(w))\n",
    "        l2_contribution = (1 - self.l_ratio) * self.l * 0.5 * np.sum(np.square(w))\n",
    "        return l1_contribution + l2_contribution\n",
    "\n",
    "    def derivation(self, w):\n",
    "        l1_derivation = self.l * self.l_ratio * np.sign(w)\n",
    "        l2_derivation = self.l * (1 - self.l_ratio) * w\n",
    "        return l1_derivation + l2_derivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LassoRegression(RegressionModel):\n",
    "        def __init__(self, lr, number_of_epochs, l):\n",
    "            regularization = ElasticPenalty(l, l_ratio=1) # penalty object\n",
    "            super().__init__(lr, number_of_epochs, regularization)\n",
    "\n",
    "            \n",
    "class RidgeRegression(RegressionModel):\n",
    "        def __init__(self, lr, number_of_epochs, l):\n",
    "            regularization = ElasticPenalty(l, l_ratio=0) # penalty object\n",
    "            super().__init__(lr, number_of_epochs, regularization)\n",
    "\n",
    "            \n",
    "class ElasticNet(RegressionModel):\n",
    "        def __init__(self, lr, number_of_epochs, l = 0.1, l_ratio = 0.5):\n",
    "            regularization = ElasticPenalty(l, l_ratio) # penalty object\n",
    "            super().__init__(lr, number_of_epochs, regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cost in iteration 10000-----> 35.50222546152582 :)\n",
      "The Cost in iteration 20000-----> 34.59132991822705 :)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.894000907362028"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model = LassoRegression(lr=5e-2, number_of_epochs=25000, l = 0.1)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "predictions = lasso_model.predict(X_test)\n",
    "mse_loss(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cost in iteration 10000-----> 1810.1660024170287 :)\n",
      "The Cost in iteration 20000-----> 1810.1660024170287 :)\n",
      "The Cost in iteration 30000-----> 1810.1660024170287 :)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "306.76062550162806"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model = RidgeRegression(lr=5e-2, number_of_epochs=30000, l = 0.1)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "predictions = ridge_model.predict(X_test)\n",
    "mse_loss(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.24it/s]\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for i in tqdm.tqdm(range(11)):\n",
    "    parameters = {\n",
    "        \"l_ratio\" : i * 0.1,\n",
    "        \"l\" : 0.1,\n",
    "        \"lr\" : 5e-2,\n",
    "        \"number_of_epochs\" : 10000\n",
    "    }\n",
    "    model = ElasticNet(**parameters)\n",
    "    model.fit(X_train, y_train, logging=False)\n",
    "    predictions = model.predict(X_test)   \n",
    "    losses.append(mse_loss(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [i * 0.1 for i in range(11)]\n",
    "y = losses\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('l ratio')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
