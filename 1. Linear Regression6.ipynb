{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><font face=\"Times New Roman\" size=5><div dir=ltr align=center>\n",
    "<font color=blue size=8>\n",
    "    Introduction to Machine Learning <br>\n",
    "<font color=red size=5>\n",
    "    Sharif University of Technology - Computer Engineering Department <br>\n",
    "    Fall 2022<br> <br>\n",
    "<font color=black size=6>\n",
    "    Homework 2: Practical - Linear Regression\n",
    "    </div>\n",
    "<br><br>\n",
    "<font size=4>\n",
    "   **Name**: Mohammad Mahdi<br>\n",
    "   **Student ID**: 98105557<br> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Times New Roman\" size=4><div dir=ltr>\n",
    "# Problem 1: Linear Regression Model (40 + 30 optional points)\n",
    "According to <a href=\"https://github.com/asharifiz/Introduction_to_Machine_Learning/blob/main/Jupyter_Notebooks/Chapter_02_Classical_Models/Linear%20regression.ipynb\"><font face=\"Roboto\">Linear Regression Notebook</font></a>, train a linear regression model on an arbitrary dataset. Explain your chosen dataset and split your data into train and test sets, then predict values for the test set using your trained model. Try to find the best hyperparameters for your model. (Using Lasso Regression, Ridge Regression or Elastic Net and comparing them will have extra optional points)\n",
    "<br> Explain each step of your workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading dataset\n",
    "This dataset is Tesla's stock from 2010 to 2020. it has some columns of opening price or highest and lowest price of the day. we try to predict closing/the last price of the stock based on the other features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-06-29</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>25.00</td>\n",
       "      <td>17.540001</td>\n",
       "      <td>23.889999</td>\n",
       "      <td>23.889999</td>\n",
       "      <td>18766300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>25.790001</td>\n",
       "      <td>30.42</td>\n",
       "      <td>23.299999</td>\n",
       "      <td>23.830000</td>\n",
       "      <td>23.830000</td>\n",
       "      <td>17187100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.92</td>\n",
       "      <td>20.270000</td>\n",
       "      <td>21.959999</td>\n",
       "      <td>21.959999</td>\n",
       "      <td>8218800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-07-02</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.10</td>\n",
       "      <td>18.709999</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>5139800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-06</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.00</td>\n",
       "      <td>15.830000</td>\n",
       "      <td>16.110001</td>\n",
       "      <td>16.110001</td>\n",
       "      <td>6866900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open   High        Low      Close  Adj Close    Volume\n",
       "0  2010-06-29  19.000000  25.00  17.540001  23.889999  23.889999  18766300\n",
       "1  2010-06-30  25.790001  30.42  23.299999  23.830000  23.830000  17187100\n",
       "2  2010-07-01  25.000000  25.92  20.270000  21.959999  21.959999   8218800\n",
       "3  2010-07-02  23.000000  23.10  18.709999  19.200001  19.200001   5139800\n",
       "4  2010-07-06  20.000000  20.00  15.830000  16.110001  16.110001   6866900"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('TSLA.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Date'],axis=1)\n",
    "y = df[\"Close\"]\n",
    "y = np.log(y)\n",
    "X = df.drop([\"Close\",\"Adj Close\"], axis=1)\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "y = y[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression mdoel closed form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionCloseForm:\n",
    "    def __init__(self):\n",
    "        self.W = None\n",
    "              \n",
    "    def train(self, X_train, y):\n",
    "        X = np.append(np.ones((X_train.shape[0], 1)), X_train , axis=1)\n",
    "        self.W = np.dot((np.linalg.inv(np.dot(X.T,X))), np.dot(X.T,y))\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        X = np.append(np.ones((X_test.shape[0], 1)), X_test , axis=1)\n",
    "        return np.dot(X, self.W)\n",
    "    \n",
    "    def mse_loss(self, pred, real):\n",
    "        diff = pred - real\n",
    "        return np.sum(diff * diff) / diff.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10331479868701765"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RegressionCloseForm()\n",
    "model.train(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "model.mse_loss(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla Linear regression with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_model = linear_model.LinearRegression()\n",
    "regr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE error on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08723812434995265"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train = regr_model.predict(X_train)\n",
    "mean_squared_error(y_train, predictions_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE error on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10331479868479447"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = regr_model.predict(X_test)\n",
    "mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.902886648192277"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation of model regression score function. it shows our model works well\n",
    "regr_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare predicted values with real ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Real</th>\n",
       "      <th>differnece</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.569079</td>\n",
       "      <td>3.449670</td>\n",
       "      <td>0.119409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.524153</td>\n",
       "      <td>3.204777</td>\n",
       "      <td>0.319376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.639355</td>\n",
       "      <td>5.633932</td>\n",
       "      <td>0.005423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.002769</td>\n",
       "      <td>5.793623</td>\n",
       "      <td>0.209146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.463839</td>\n",
       "      <td>5.558063</td>\n",
       "      <td>0.094224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>4.651724</td>\n",
       "      <td>5.187386</td>\n",
       "      <td>0.535661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>5.398390</td>\n",
       "      <td>5.528873</td>\n",
       "      <td>0.130483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>3.501618</td>\n",
       "      <td>3.221273</td>\n",
       "      <td>0.280345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>6.131629</td>\n",
       "      <td>5.845456</td>\n",
       "      <td>0.286174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>4.837394</td>\n",
       "      <td>5.214555</td>\n",
       "      <td>0.377161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>484 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Predicted      Real  differnece\n",
       "0     3.569079  3.449670    0.119409\n",
       "1     3.524153  3.204777    0.319376\n",
       "2     5.639355  5.633932    0.005423\n",
       "3     6.002769  5.793623    0.209146\n",
       "4     5.463839  5.558063    0.094224\n",
       "..         ...       ...         ...\n",
       "479   4.651724  5.187386    0.535661\n",
       "480   5.398390  5.528873    0.130483\n",
       "481   3.501618  3.221273    0.280345\n",
       "482   6.131629  5.845456    0.286174\n",
       "483   4.837394  5.214555    0.377161\n",
       "\n",
       "[484 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison = pd.DataFrame({'Predicted':predictions.flatten(),'Real':y_test.flatten(), 'differnece':np.abs(predictions - y_test).flatten()})\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems that our model worked well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10157513349639632"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticnet_model = ElasticNet(alpha=0.1, l1_ratio=1, max_iter=2000)\n",
    "elasticnet_model.fit(X_train, y_train)\n",
    "predictions = elasticnet_model.predict(X_test)\n",
    "mean_squared_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regression model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel:\n",
    "    \n",
    "    def __init__(self, lr, number_of_epochs, regularization=None):\n",
    "        self.m = None # samples\n",
    "        self.n = None # features\n",
    "        self.W = None # weight\n",
    "        self.regularization = regularization # penalty object\n",
    "        self.lr = lr # learning rate\n",
    "        self.epoch = number_of_epochs # iteration\n",
    "        self.train_mean = None\n",
    "        self.train_std = None\n",
    "        \n",
    "    def __calculate_cost(self, y, y_pred):\n",
    "        cost = (1 / (2 * self.m)) * np.sum(np.square(y_pred-y))\n",
    "        if self.regularization:\n",
    "            return cost + self.regularization(self.W) \n",
    "        return cost\n",
    "    \n",
    "    def __initialize(self, X):\n",
    "        X2 = np.insert(X, 0, 1, axis=1)\n",
    "        self.m, self.n = X2.shape\n",
    "        self.W = np.random.rand(self.n, 1)\n",
    "        return X2\n",
    "    \n",
    "    def __update_weights(self, X, y, y_pred):\n",
    "        dw = np.dot(X.T, (y_pred - y)) / self.m\n",
    "        if self.regularization:\n",
    "            dw += self.regularization.derivation(self.W)\n",
    "        \n",
    "        self.W -= self.lr * dw\n",
    "    \n",
    "    def __feature_scaling(self, data, is_training = False):\n",
    "        data2 = data.copy()\n",
    "        number_of_columns = data.shape[1]\n",
    "        if is_training:\n",
    "            self.train_mean = [0] * number_of_columns\n",
    "            self.train_std = [0] * number_of_columns\n",
    "        for i in range(number_of_columns):\n",
    "            if is_training:\n",
    "                self.train_mean[i] = np.mean(data2[:,i])\n",
    "                self.train_std[i] = np.std(data2[:,i])\n",
    "            data2[:,i] = (data2[:,i] - self.train_mean[i]) / self.train_std[i]\n",
    "        return data2\n",
    "        \n",
    "    def fit(self, X_train, y_train, logging=True):\n",
    "        if isinstance(X_train, pd.core.frame.DataFrame):\n",
    "            X_train = X_train.to_numpy()\n",
    "        if isinstance(y_train, pd.core.frame.DataFrame):\n",
    "            y_train = y_train.to_numpy()\n",
    "        X = self.__feature_scaling(X_train, is_training=True)\n",
    "        \n",
    "        X = self.__initialize(X)\n",
    "        y = y_train.reshape(self.m, -1)\n",
    "        for e in range(1, self.epoch+1):\n",
    "            y_pred = np.dot(X, self.W)\n",
    "            cost = self.__calculate_cost(y, y_pred)\n",
    "            self.__update_weights(X, y, y_pred)\n",
    "            if logging and e % 1000 == 0:\n",
    "                print(f\"The Cost in iteration {e}-----> {cost} :)\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        if isinstance(X_test, pd.core.frame.DataFrame):\n",
    "            X_test = X_test.to_numpy()\n",
    "        X_test2 = self.__feature_scaling(X_test)\n",
    "        X_test2 = np.insert(X_test2, 0 , 1, axis= 1)\n",
    "        return np.dot(X_test2, self.W) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(pred, real):\n",
    "    diff = pred - real\n",
    "    return np.sum(diff * diff) / diff.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cost in iteration 1000-----> 0.04605843537828089 :)\n",
      "The Cost in iteration 2000-----> 0.04584924111492425 :)\n",
      "The Cost in iteration 3000-----> 0.04565875640229549 :)\n",
      "The Cost in iteration 4000-----> 0.04548524801936515 :)\n",
      "The Cost in iteration 5000-----> 0.04532714777950694 :)\n",
      "The Cost in iteration 6000-----> 0.045183036493953464 :)\n",
      "The Cost in iteration 7000-----> 0.045051629516130134 :)\n",
      "The Cost in iteration 8000-----> 0.04493176370947267 :)\n",
      "The Cost in iteration 9000-----> 0.04482238569710908 :)\n",
      "The Cost in iteration 10000-----> 0.04472254126597423 :)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10162681185075381"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_model_custom = RegressionModel(lr=0.1, number_of_epochs=10000)\n",
    "reg_model_custom.fit(X_train, y_train)\n",
    "predictions = reg_model_custom.predict(X_test)\n",
    "mse_loss(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:26<00:00,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best learning rate: 0.05\n",
      "best loss: 0.10159923303360809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_loss = np.inf\n",
    "best_lr = None\n",
    "lr_list = [1e-4,5e-4,1e-3,5e-3,1e-2,5e-2,8e-2,1e-1,2e-1,5e-1]\n",
    "for lr in tqdm.tqdm(lr_list):\n",
    "    reg_model_custom = RegressionModel(lr=lr, number_of_epochs=10000)\n",
    "    reg_model_custom.fit(X_train, y_train, logging=False)\n",
    "    predictions = reg_model_custom.predict(X_test)\n",
    "    loss = mse_loss(y_test, predictions)\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_lr = lr\n",
    "print(f'best learning rate: {best_lr}')\n",
    "print(f'best loss: {best_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElasticPenalty:\n",
    "    \n",
    "    def __init__(self, l = 0.1, l_ratio = 0.5):\n",
    "        self.l = l \n",
    "        self.l_ratio = l_ratio\n",
    "\n",
    "    def __call__(self, w):\n",
    "        l1_contribution = self.l_ratio * self.l * np.sum(np.abs(w))\n",
    "        l2_contribution = (1 - self.l_ratio) * self.l * 0.5 * np.sum(np.square(w))\n",
    "        return l1_contribution + l2_contribution\n",
    "\n",
    "    def derivation(self, w):\n",
    "        l1_derivation = self.l * self.l_ratio * np.sign(w)\n",
    "        l2_derivation = self.l * (1 - self.l_ratio) * w\n",
    "        return l1_derivation + l2_derivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LassoRegression(RegressionModel):\n",
    "        def __init__(self, lr, number_of_epochs, l):\n",
    "            regularization = ElasticPenalty(l, l_ratio=1) # penalty object\n",
    "            super().__init__(lr, number_of_epochs, regularization)\n",
    "\n",
    "            \n",
    "class RidgeRegression(RegressionModel):\n",
    "        def __init__(self, lr, number_of_epochs, l):\n",
    "            regularization = ElasticPenalty(l, l_ratio=0) # penalty object\n",
    "            super().__init__(lr, number_of_epochs, regularization)\n",
    "\n",
    "            \n",
    "class ElasticNet(RegressionModel):\n",
    "        def __init__(self, lr, number_of_epochs, l = 0.1, l_ratio = 0.5):\n",
    "            regularization = ElasticPenalty(l, l_ratio) # penalty object\n",
    "            super().__init__(lr, number_of_epochs, regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cost in iteration 1000-----> 0.6193578999456555 :)\n",
      "The Cost in iteration 2000-----> 0.6192494944562983 :)\n",
      "The Cost in iteration 3000-----> 0.6192416336631836 :)\n",
      "The Cost in iteration 4000-----> 0.6192302714170003 :)\n",
      "The Cost in iteration 5000-----> 0.6192070767980253 :)\n",
      "The Cost in iteration 6000-----> 0.6192746114718974 :)\n",
      "The Cost in iteration 7000-----> 0.6191771288183616 :)\n",
      "The Cost in iteration 8000-----> 0.6191640090030768 :)\n",
      "The Cost in iteration 9000-----> 0.6191965137597475 :)\n",
      "The Cost in iteration 10000-----> 0.6192182416881671 :)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1104786285363526"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model = LassoRegression(lr=5e-2, number_of_epochs=10000, l = 0.1)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "predictions = lasso_model.predict(X_test)\n",
    "mse_loss(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cost in iteration 1000-----> 1.1333896232734062 :)\n",
      "The Cost in iteration 2000-----> 1.133389425264672 :)\n",
      "The Cost in iteration 3000-----> 1.1333894252563594 :)\n",
      "The Cost in iteration 4000-----> 1.1333894252563592 :)\n",
      "The Cost in iteration 5000-----> 1.1333894252563592 :)\n",
      "The Cost in iteration 6000-----> 1.133389425256359 :)\n",
      "The Cost in iteration 7000-----> 1.1333894252563592 :)\n",
      "The Cost in iteration 8000-----> 1.1333894252563592 :)\n",
      "The Cost in iteration 9000-----> 1.1333894252563592 :)\n",
      "The Cost in iteration 10000-----> 1.1333894252563592 :)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.27882311152958134"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model = RidgeRegression(lr=5e-2, number_of_epochs=10000, l = 0.1)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "predictions = ridge_model.predict(X_test)\n",
    "mse_loss(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:31<00:00,  2.90s/it]\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for i in tqdm.tqdm(range(11)):\n",
    "    parameters = {\n",
    "        \"l_ratio\" : i * 0.1,\n",
    "        \"l\" : 0.1,\n",
    "        \"lr\" : 5e-2,\n",
    "        \"number_of_epochs\" : 10000\n",
    "    }\n",
    "    model = ElasticNet(**parameters)\n",
    "    model.fit(X_train, y_train, logging=False)\n",
    "    predictions = model.predict(X_test)   \n",
    "    losses.append(mse_loss(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [i * 0.1 for i in range(11)]\n",
    "y = losses\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('l ratio')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01,\n",
       " 0.02,\n",
       " 0.03,\n",
       " 0.04,\n",
       " 0.05,\n",
       " 0.06,\n",
       " 0.07,\n",
       " 0.08,\n",
       " 0.09,\n",
       " 0.1,\n",
       " 0.2,\n",
       " 0.30000000000000004,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.6000000000000001,\n",
       " 0.7000000000000001,\n",
       " 0.8,\n",
       " 0.9]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(0.01 * i for i in range(1,10)) + list(0.1 * i for i in range(1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
